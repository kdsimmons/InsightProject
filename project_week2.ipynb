{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import bs4\n",
      "import re, numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import requests, urllib2\n",
      "import tweepy\n",
      "\n",
      "%matplotlib inline\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scrape_bbb_urls():\n",
      "    # import URL into beautiful soup object\n",
      "    give_org_urls = [\"http://give.org/search/?term=multiple+sclerosis&location=&FilterAccredited=false&tobid=\", \n",
      "                     \"http://give.org/search/?page=2&term=multiple+sclerosis&location=&FilterAccredited=false&tobid=\", \n",
      "                     \"http://give.org/search/?page=3&term=multiple+sclerosis&location=&FilterAccredited=false&tobid=\"]\n",
      "    bbb_soups = []\n",
      "    for give_org_url in give_org_urls:\n",
      "        response = requests.get(give_org_url)\n",
      "        bbb_soups.append(bs4.BeautifulSoup(response.text))\n",
      "        \n",
      "    return bbb_soups\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_bbb_info(bbb_soups):\n",
      "    # pull out charity links and info\n",
      "    # NOTE: May need permission to include links to BBB. I didn't find any info on restrictions in pulling information.\n",
      "    charities = []\n",
      "    for soup in bbb_soups:\n",
      "        bbb_table = soup.select('div.search table')[0].tbody \n",
      "        for row in bbb_table.findAll('tr'):\n",
      "            charity_data = {}\n",
      "            charity_data['name'] = row.select('a.charity-link')[0].get_text()\n",
      "            charity_data['bbb_link'] = row.select('a.charity-link')[0].attrs.get('href')\n",
      "            accred_seal = row.select('img.charity-search-seal')\n",
      "            if accred_seal:\n",
      "                charity_data['bbb_accred'] = accred_seal[0].attrs.get('alt')\n",
      "            else:\n",
      "                charity_data['bbb_accred'] = row.select('div.accreditation-mobile')[0].get_text()\n",
      "            charity_data['address'] = row.select('div.accreditation-mobile')[0].next_sibling.strip()\n",
      "            charity_data['city'] = row.select('div.accreditation-mobile')[0].next_sibling.next_sibling.next_sibling.strip()\n",
      "            \n",
      "            charities.append(charity_data)\n",
      "            \n",
      "    return charities\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bbb_soups = scrape_bbb_urls()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bbb_charities = clean_bbb_info(bbb_soups)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_charity_links(charities):\n",
      "    # Use BBB pages to get links to each charity's website\n",
      "    \n",
      "    for charity in charities:\n",
      "        soup = bs4.BeautifulSoup(requests.get(charity['bbb_link']).text)\n",
      "        if len(soup.select('div.charity-contact')) > 0:\n",
      "            charity['link'] = soup.select('div.charity-contact')[0].a.attrs.get('href')\n",
      "        elif len(soup.select('div.charity-detail-text')) > 0:\n",
      "            charity['link'] = soup.select('div.charity-detail-text')[0].a.attrs.get('href')\n",
      "        elif len(soup.select('a#ctl00_ContentPlaceHolder1_aWebUrl')) > 0:\n",
      "            charity['link'] = soup.select('a#ctl00_ContentPlaceHolder1_aWebUrl')[0].attrs.get('href')\n",
      "        else:\n",
      "            charity['link'] = ''\n",
      "    # TO DO: should add text search for websites printed as text rather than link\n",
      "    \n",
      "    return charities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "charities_with_links = get_charity_links(bbb_charities)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scrape_social_media(charities):\n",
      "    # Find Facebook likes and Twitter followers for each charity\n",
      "    # TO DO: Find the right FB/Twitter account, e.g. for National MS Society chapters.\n",
      "    for charity in charities:\n",
      "        if charity['link'] == '':\n",
      "            charity['facebook_link'] = ''\n",
      "            charity['twitter_link'] = ''\n",
      "        else: \n",
      "            try:\n",
      "                page = urllib2.urlopen(urllib2.Request(charity['link'], headers={'User-Agent' : 'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11'}))\n",
      "                target_soup = bs4.BeautifulSoup(page.read(), 'html.parser')\n",
      "            except:\n",
      "                print charity['name']\n",
      "                continue\n",
      "    \n",
      "            try:\n",
      "                fblink = target_soup.select('a[href*=facebook.com]')[0].attrs.get('href')\n",
      "            except IndexError:\n",
      "                fblink = ''\n",
      "            charity['facebook_link'] = fblink \n",
      "            \n",
      "            try:\n",
      "                twlink = target_soup.select('a[href*=twitter.com]')[0].attrs.get('href')\n",
      "            except IndexError:\n",
      "                twlink = ''\n",
      "            charity['twitter_link'] = twlink\n",
      "            \n",
      "    return charities\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "charities_with_social = scrape_social_media(charities_with_links)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_twitter_followers(charities):\n",
      "    auth = tweepy.OAuthHandler('Ch5gSBZ074a7fp5LXJwa3qOY2', 'BtrdY7YSzMqWI54mheMlbWlMArhzB07HhLzq7vfiAYgIJrCiVZ')\n",
      "    auth.set_access_token('1230382532-Gd6RxPhwgaK91tlcZymzXFqlheRz1hJWrYG7Na9', 'W8tyAbCiGQ8oRS2hFk6NI45SRrdauazIQe3d7B3LAseUX')\n",
      "    \n",
      "    api = tweepy.API(auth)\n",
      "    \n",
      "    for charity in charities:\n",
      "        if charity['twitter_link'] == '':\n",
      "            charity['twitter_followers'] = 0\n",
      "        else:\n",
      "            try:\n",
      "                twitterid = re.findall('https://twitter.com/(.*)', charity['twitter_link'])[0]\n",
      "                user = api.get_user(twitterid)\n",
      "                charity['twitter_followers'] = user.followers_count\n",
      "            except:\n",
      "                print charity['name']\n",
      "                charity['twitter_followers'] = 0\n",
      "                continue\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "char_with_twitter = get_twitter_followers(charities_with_social)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Multiple Sclerosis Association of America\n",
        "National Multiple Sclerosis Society Arizona Chapter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "National Multiple Sclerosis Society"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "National Multiple Sclerosis Society"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Can Do Multiple Sclerosis\n",
        "National Multiple Sclerosis Society - Long Island Chapter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "National Multiple Sclerosis Society, Ohio Buckeye Chapter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "National Multiple Sclerosis Society Greater Northwest Chapter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "National Multiple Sclerosis Society-Wisconsin Chapter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "National Multiple Sclerosis Society - Nyc Chapter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "National Multiple Sclerosis Society Utah-Southern Idaho Chapter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "National Multiple Sclerosis Society Pacific South Coast Chapter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "National Multiple Sclerosis Society Kentucky Southeast Indiana Chapter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}