{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import bs4\n",
      "import re, numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import requests, urllib2\n",
      "import tweepy\n",
      "import pymysql as mdb\n",
      "\n",
      "%matplotlib inline\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chosen_disease = \"alzheimer's disease\"\n",
      "clean_disease_name = ' '.join(chosen_disease.lower().replace('\\'s disease','').split())\n",
      "# TO DO: allow synonymous names (e.g. colon vs colorectal cancer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scrape_bbb_urls(disease):\n",
      "    # import URL into beautiful soup object\n",
      "\n",
      "    dis_as_str = '+'.join(disease.split())\n",
      "    base_url = \"http://give.org\"\n",
      "    give_org_url = base_url + \"/search/?term=\" + dis_as_str + \"&location=&FilterAccredited=false&tobid=\"\n",
      "    \n",
      "    bbb_soups = []\n",
      "\n",
      "    # loop through all pages of search results\n",
      "    more_pages = True \n",
      "    while(more_pages):\n",
      "        response = requests.get(give_org_url)\n",
      "        soup = bs4.BeautifulSoup(response.text)\n",
      "        bbb_soups.append(soup)\n",
      "        next_link = soup.select('a[href*=search/?page]')\n",
      "        \n",
      "        more_pages = False\n",
      "        for link in next_link:\n",
      "            if re.findall('.*Next.*', link.getText()):\n",
      "                give_org_url = base_url + link.attrs['href']\n",
      "                more_pages = True\n",
      "\n",
      "    return bbb_soups\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_bbb_info(bbb_soups,disease):\n",
      "    # pull out charity links and info\n",
      "    # NOTE: May need permission to include links to BBB. I didn't find any info on restrictions in pulling information.\n",
      "    charities = []\n",
      "    for soup in bbb_soups:\n",
      "        bbb_table = soup.select('div.search table')[0].tbody \n",
      "        for row in bbb_table.findAll('tr'):\n",
      "            charity_data = {}\n",
      "            charity_data['disease'] = disease\n",
      "            charity_data['name'] = row.select('a.charity-link')[0].get_text().replace(u'\\u2019', u'\\'')\n",
      "            charity_data['bbb_link'] = row.select('a.charity-link')[0].attrs.get('href')\n",
      "            accred_seal = row.select('img.charity-search-seal')\n",
      "            if accred_seal:\n",
      "                charity_data['bbb_accred'] = accred_seal[0].attrs.get('alt')\n",
      "            else:\n",
      "                charity_data['bbb_accred'] = row.select('div.accreditation-mobile')[0].get_text()\n",
      "            charity_data['address'] = row.select('div.accreditation-mobile')[0].next_sibling.strip().replace(u'\\u2019', u'\\'')\n",
      "            charity_data['city'] = row.select('div.accreditation-mobile')[0].next_sibling.next_sibling.next_sibling.strip()\n",
      "            \n",
      "            charities.append(charity_data)\n",
      "     \n",
      "    # get year of incorporation and other data where possible\n",
      "    for charity in charities:\n",
      "        response = requests.get(charity['bbb_link'])\n",
      "        soup = bs4.BeautifulSoup(response.text)\n",
      "        \n",
      "        # year of incorporation and stated purpose \n",
      "        try:\n",
      "            purpdiv = soup.select('div#purpose')[0]\n",
      "            tag = purpdiv.findNext(text=re.compile('Year, State Incorporated'))\n",
      "            charity['year_incorporated'] = re.findall('[1-2][0-9][0-9][0-9]', tag.findNext('p').text)[0]\n",
      "            tag = purpdiv.findNext(text=re.compile('Stated Purpose'))\n",
      "            charity['purpose'] = tag.findNext('p').get_text().strip('\"').replace(u'\\u2019', u'\\'')\n",
      "        except:\n",
      "            charity['year_incorporated'] = 0\n",
      "            charity['purpose'] = ''\n",
      "\n",
      "        # board and staff size\n",
      "        try:\n",
      "            govdiv = soup.select('div#governance')[0]\n",
      "            charity['board_size'] = govdiv.findNext(text=re.compile('Board Size')).findNext('p').text\n",
      "            charity['staff_size'] = govdiv.findNext(text=re.compile('Paid Staff Size')).findNext('p').text\n",
      "        except:\n",
      "            charity['board_size'] = 0\n",
      "            charity['staff_size'] = 0\n",
      "\n",
      "        # tax exempt status\n",
      "        try:\n",
      "            taxdiv = soup.select('div#taxstatus')[0]\n",
      "            charity['tax_status'] = taxdiv.findNext('p').text\n",
      "        except:\n",
      "            charity['tax_status'] = 'unknown'\n",
      "\n",
      "    return charities\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bbb_soups = scrape_bbb_urls(clean_disease_name)\n",
      "len(bbb_soups)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bbb_charities = clean_bbb_info(bbb_soups,clean_disease_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print bbb_charities[0]['tax_status']==bbb_charities[3]['tax_status']\n",
      "bbb_charities[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "to rapidly accelerate the discovery of drugs to prevent, treat and cure Alzheimer's disease, related dementias and cognitive aging.\" \n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "str(purpose.replace(u'\\u2019', u'\\''))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "\"to fund research with the highest probability of slowing, stopping or reversing Alzheimer's through venture based philanthropy with all organizational expenses paid for by the Board, allowing all public contributions to directly fund Alzheimer's disease research.\""
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_charity_links(charities):\n",
      "    # Use BBB pages to get links to each charity's website\n",
      "    \n",
      "    for charity in charities:\n",
      "        soup = bs4.BeautifulSoup(requests.get(charity['bbb_link']).text)\n",
      "        if len(soup.select('div.charity-contact')) > 0:\n",
      "            charity['link'] = soup.select('div.charity-contact')[0].a.attrs.get('href')\n",
      "        elif len(soup.select('div.charity-detail-text')) > 0:\n",
      "            charity['link'] = soup.select('div.charity-detail-text')[0].a.attrs.get('href')\n",
      "        elif len(soup.select('a#ctl00_ContentPlaceHolder1_aWebUrl')) > 0:\n",
      "            charity['link'] = soup.select('a#ctl00_ContentPlaceHolder1_aWebUrl')[0].attrs.get('href')\n",
      "        else:\n",
      "            charity['link'] = ''\n",
      "    # TO DO: should add text search for websites printed as text rather than link\n",
      "    \n",
      "    return charities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "charities_with_links = get_charity_links(bbb_charities)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(charities_with_links)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "49"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scrape_social_media(charities):\n",
      "    # Find Facebook likes and Twitter followers for each charity\n",
      "    # TO DO: Find the right FB/Twitter account, e.g. for National MS Society chapters.\n",
      "    for charity in charities:\n",
      "        if charity['link'] == '':\n",
      "            charity['facebook_link'] = ''\n",
      "            charity['twitter_link'] = ''\n",
      "        else: \n",
      "            try:\n",
      "                page = urllib2.urlopen(urllib2.Request(charity['link'], headers={'User-Agent' : 'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11'}))\n",
      "                target_soup = bs4.BeautifulSoup(page.read(), 'html.parser')\n",
      "            except:\n",
      "                print charity['name']\n",
      "                charity['facebook_link'] = ''\n",
      "                charity['twitter_link'] = ''\n",
      "                continue\n",
      "    \n",
      "            try:\n",
      "                fblink = target_soup.select('a[href*=facebook.com]')[0].attrs.get('href')\n",
      "            except IndexError:\n",
      "                fblink = ''\n",
      "            charity['facebook_link'] = fblink \n",
      "            \n",
      "            try:\n",
      "                twlink = target_soup.select('a[href*=twitter.com]')[0].attrs.get('href')\n",
      "            except IndexError:\n",
      "                twlink = ''\n",
      "            charity['twitter_link'] = twlink\n",
      "            \n",
      "    return charities\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "charities_with_social = scrape_social_media(charities_with_links)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(charities_with_social)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "49"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_twitter_followers(charities):\n",
      "    # import authorization info \n",
      "    twauth = pd.DataFrame.from_csv('/home/kristy/Documents/auth_codes/twitter_access.csv')\n",
      "    auth = tweepy.OAuthHandler(twauth.consumer_key['twitter'], twauth.consumer_secret['twitter'])\n",
      "    auth.set_access_token(twauth.access_token['twitter'], twauth.access_secret['twitter'])\n",
      "    \n",
      "    api = tweepy.API(auth)\n",
      "    \n",
      "    for charity in charities:\n",
      "        if charity['twitter_link'] == '':\n",
      "            charity['twitter_followers'] = 0\n",
      "        else:\n",
      "            try:\n",
      "                twitterid = re.findall('https://twitter.com/(.*)', charity['twitter_link'])[0]\n",
      "                user = api.get_user(twitterid)\n",
      "                charity['twitter_followers'] = user.followers_count\n",
      "            except:\n",
      "                charity['twitter_followers'] = 0\n",
      "                continue\n",
      "                \n",
      "    return charities\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "char_with_twitter = get_twitter_followers(charities_with_social)\n",
      "len(char_with_twitter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "49"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_char_nav_info(dictlist): \n",
      "    for charity in dictlist:\n",
      "        # get link to Charity Navigator's website on this charity\n",
      "        words = '+'.join(charity['name'].split())\n",
      "        url = ('https://www.charitynavigator.org/index.cfm?keyword_list=' + words \n",
      "               + '&nameonly=1&Submit2=Search&bay=search.results')\n",
      "        response = requests.get(url)\n",
      "        soup = bs4.BeautifulSoup(response.text)\n",
      "        if len(soup.select('p.rating')) > 0:\n",
      "            charity['cn_link'] = soup.select('p.rating')[0].a.attrs.get('href')\n",
      "            charity['cn_rated'] = 'Rated'\n",
      "        else:\n",
      "            url = ('https://www.charitynavigator.org/index.cfm?keyword_list=' + words \n",
      "                   + '&nameonly=1&Submit2=Search&bay=search.results2')\n",
      "            response = requests.get(url)\n",
      "            soup = bs4.BeautifulSoup(response.text)\n",
      "            if len(soup.select('p.orgname')) > 0:\n",
      "                charity['cn_link'] = soup.select('p.orgname')[0].a.attrs.get('href')\n",
      "                charity['cn_rated'] = 'Unrated'                \n",
      "            else:\n",
      "                print charity['name'] + \": No Charity Navigator link.\"\n",
      "                charity['cn_link'] = ''\n",
      "                charity['cn_rated'] = ''\n",
      "            charity['cn_overall'] = float('nan')\n",
      "            charity['cn_financial'] = float('nan')\n",
      "            charity['cn_acct_transp'] = float('nan')\n",
      "            continue\n",
      "        \n",
      "        # get Charity Navigator data \n",
      "        charsoup = bs4.BeautifulSoup(requests.get(charity['cn_link']).text)\n",
      "        strongtags = charsoup.select('strong')\n",
      "        overall_cells = []\n",
      "        fin_cells = []\n",
      "        acct_cells = []\n",
      "        for tg in strongtags:\n",
      "            if tg.text == \"Overall\":\n",
      "                overall_cells.append(float(tg.parent.nextSibling.nextSibling.text))\n",
      "            elif tg.text == \"Financial\":\n",
      "                fin_cells.append(float(tg.parent.nextSibling.nextSibling.text))\n",
      "            elif tg.text == \"Accountability & Transparency\":\n",
      "                acct_cells.append(float(tg.parent.nextSibling.nextSibling.text))\n",
      "        # include overall rating\n",
      "        if len(overall_cells) == 1:\n",
      "            charity['cn_overall'] = overall_cells[0]\n",
      "        elif len(overall_cells) > 1:\n",
      "            print charity['name'] + \": Too many candidate cells for Overall.\"\n",
      "            charity['cn_overall'] = overall_cells[0]\n",
      "        else:\n",
      "            print charity['name'] + \": No Overall cells.\"\n",
      "            charity['cn_overall'] = 0\n",
      "        # include financial rating\n",
      "        if len(fin_cells) == 1:\n",
      "            charity['cn_financial'] = fin_cells[0]\n",
      "        elif len(fin_cells) > 1:\n",
      "            print char['name'] + \": Too many candidate cells for Financial.\"\n",
      "            charity['cn_financial'] = fin_cells[0]\n",
      "        else:\n",
      "            #print \"No Financial cells\"\n",
      "            charity['cn_financial'] = 0\n",
      "        # include accountability rating\n",
      "        if len(acct_cells) == 1:\n",
      "            charity['cn_acct_transp'] = acct_cells[0]\n",
      "        elif len(acct_cells) > 1:\n",
      "            print charity['name'] + \": Too many candidate cells for Accountability & Transparency.\"\n",
      "            charity['cn_acct_transp'] = acct_cells[0]\n",
      "        else:\n",
      "            #print \"No Accountability & Transparency cells\"\n",
      "            charity['cn_acct_transp'] = 0\n",
      "            \n",
      "         # compensation of leaders\n",
      "        compensation = []\n",
      "        for heading in charsoup.select('h2'):\n",
      "            comphead = re.findall('Compensation of Leaders', heading.text)\n",
      "            if len(comphead) > 0:\n",
      "                comptable = heading.nextSibling.nextSibling\n",
      "                \n",
      "                for row in comptable.findAll(\"tr\"):\n",
      "                    for cell in row.findAll(\"td\"):\n",
      "                        if re.findall(\"\\$\", cell.text):\n",
      "                            compensation.append(cell.text.strip())\n",
      "        charity['leader_compensation'] = '+'.join(compensation)\n",
      "        \n",
      "        # basic financial info\n",
      "        expenses = charsoup.find('a', onmouseover=re.compile('Total Functional Expenses')).findNext('td').text\n",
      "        contributions = charsoup.find('strong', text=re.compile('Total Contributions')).findNext('td').text\n",
      "        revenue = charsoup.find('strong', text=re.compile('TOTAL REVENUE')).findNext('td').text\n",
      "\n",
      "        charity['total_expenses'] = int(expenses.strip('$').replace(',', ''))\n",
      "        charity['total_contributions'] = int(contributions.strip('$').replace(',', ''))\n",
      "        charity['total_revenue'] = int(revenue.strip('$').replace(',', ''))\n",
      "        \n",
      "        metrics = charsoup.find(text=re.compile('Financial Performance Metrics'))\n",
      "        program = metrics.findNext('a', onmouseover=re.compile('Program Expenses')).findNext('td').text\n",
      "        administrative = metrics.findNext('a', onmouseover=re.compile('Administrative Expenses')).findNext('td').text\n",
      "        fundraising = metrics.findNext('a', onmouseover=re.compile('Fundraising Expenses')).findNext('td').text\n",
      "        \n",
      "        charity['percent_program'] = float(program.strip('%'))\n",
      "        charity['percent_admin'] = float(administrative.strip('%'))\n",
      "        charity['percent_fund'] = float(fundraising.strip('%'))\n",
      "        \n",
      "    return dictlist\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "char_with_nav_link = get_char_nav_info(char_with_twitter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "panda_char = pd.DataFrame(char_with_nav_link)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make sure to do sudo mysqld_safe from command line first\n",
      "def convert_to_sql(pandadf,disease):\n",
      "    mysqlauth = pd.DataFrame.from_csv('/home/kristy/Documents/auth_codes/mysql_user.csv')\n",
      "    user = mysqlauth.username[0]\n",
      "    password = mysqlauth.password[0]\n",
      "\n",
      "    con = mdb.connect('localhost', user, password, 'charity_data')\n",
      "    \n",
      "    table_name = '_'.join(disease.split())\n",
      "    print table_name\n",
      "    with con:\n",
      "        cur = con.cursor()\n",
      "        \n",
      "        # set up table\n",
      "#        cur.execute(\"DROP TABLE IF EXISTS charities_sql\")\n",
      "        cur.execute(\"DROP TABLE IF EXISTS \" + str(table_name))\n",
      "        cur.execute(\"\\\n",
      "            CREATE TABLE \" + str(table_name) + \"(\\\n",
      "                id INT PRIMARY KEY AUTO_INCREMENT,\\\n",
      "                disease VARCHAR(255),\\\n",
      "                name VARCHAR(255),\\\n",
      "                address VARCHAR(255),\\\n",
      "                city VARCHAR(255),\\\n",
      "                link VARCHAR(255),\\\n",
      "                bbb_link VARCHAR(255),\\\n",
      "                facebook_link VARCHAR(255),\\\n",
      "                twitter_link VARCHAR(255),\\\n",
      "                cn_link VARCHAR(255),\\\n",
      "                bbb_accred VARCHAR(255),\\\n",
      "                year_incorporated INT,\\\n",
      "                purpose VARCHAR(255),\\\n",
      "                board_size INT,\\\n",
      "                staff_size INT,\\\n",
      "                tax_status VARCHAR(255),\\\n",
      "                cn_rated VARCHAR(255),\\\n",
      "                cn_overall FLOAT(8,4),\\\n",
      "                cn_financial FLOAT(8,4),\\\n",
      "                cn_acct_transp FLOAT(8,4),\\\n",
      "                leader_compensation VARCHAR(255),\\\n",
      "                total_expenses INT,\\\n",
      "                total_contributions INT,\\\n",
      "                total_revenue INT,\\\n",
      "                percent_program FLOAT(6,2),\\\n",
      "                percent_admin FLOAT(6,2),\\\n",
      "                percent_fund FLOAT(6,2),\\\n",
      "                facebook_likes INT,\\\n",
      "                twitter_followers INT\\\n",
      "           )\"\\\n",
      "        ) \n",
      "        \n",
      "        facebook_likes_placeholder = 0 # not scraped yet\n",
      "\n",
      "        print \"\\nTotal records: \" + str(len(pandadf)) + \"\\n\"\n",
      "        for idx in range(len(pandadf)):\n",
      "            print idx\n",
      "            value_str = (\"\\\"\" + str(pandadf.name[idx]) + \"\\\",\\\"\" + str(pandadf.disease[idx]) + \"\\\",\\\"\" + str(pandadf.address[idx]) + \"\\\",\\\"\" \n",
      "                         + str(pandadf.city[idx]) + \"\\\",\\\"\" + str(pandadf.link[idx]) + \"\\\",\\\"\" + str(pandadf.bbb_link[idx])\n",
      "                         + \"\\\",\\\"\" + str(pandadf.facebook_link[idx]) + \"\\\",\\\"\" + str(pandadf.twitter_link[idx]) + \"\\\",\\\"\" \n",
      "                         + str(pandadf.cn_link[idx]) + \"\\\",\\\"\" + str(pandadf.bbb_accred[idx]) + \"\\\",\\\"\" + str(pandadf.year_incorporated[idx])\n",
      "                         + \"\\\",\\\"\" + str(pandadf.purpose[idx]) + \"\\\",\\\"\" + str(pandadf.board_size[idx]) + \"\\\",\\\"\" + str(pandadf.staff_size[idx]) + \"\\\",\\\"\" \n",
      "                         + str(pandadf.tax_status[idx]) + \"\\\",\\\"\" + str(pandadf.cn_rated[idx])\n",
      "                         + \"\\\",\\\"\" + str(pandadf.cn_overall[idx]) + \"\\\",\\\"\" + str(pandadf.cn_financial[idx]) + \"\\\",\\\"\" + str(pandadf.cn_acct_transp[idx]) \n",
      "                         + \"\\\",\\\"\" + str(pandadf.leader_compensation[idx]) + \"\\\",\\\"\" + str(pandadf.total_expenses[idx]) + \"\\\",\\\"\" \n",
      "                         + str(pandadf.total_contributions[idx]) + \"\\\",\\\"\" + str(pandadf.total_revenue[idx]) + \"\\\",\\\"\" \n",
      "                         + str(pandadf.percent_program[idx]) + \"\\\",\\\"\" + str(pandadf.percent_admin[idx]) + \"\\\",\\\"\" + str(pandadf.percent_fund[idx])\n",
      "                         + \"\\\",\\\"\" + str(facebook_likes_placeholder) + \"\\\",\\\"\" + str(pandadf.twitter_followers[idx]) + \"\\\"\")\n",
      "            cur.execute(\"INSERT INTO \" + str(table_name) + \"(name, disease, address, city, link, bbb_link, facebook_link, twitter_link, cn_link, bbb_accred, \\\n",
      "                         year_incorporated, purpose, board_size, staff_size, tax_status, cn_rated, cn_overall, cn_financial, cn_acct_transp, \\\n",
      "                         leader_compensation, total_expenses, \\\n",
      "                         total_contributions, total_revenue, percent_program, percent_admin, percent_fund, facebook_likes, twitter_followers) \\\n",
      "                         VALUES(\" + value_str + \")\")\n",
      "        \n",
      "        cur.execute(\"SELECT * FROM \" + str(table_name))\n",
      "        rows = cur.fetchall()\n",
      "        #for row in rows:\n",
      "            #print row\n",
      "\n",
      "    return rows\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sqlrows = convert_to_sql(panda_char,clean_disease_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alzheimer\n",
        "\n",
        "Total records: 49\n"
       ]
      },
      {
       "ename": "UnicodeEncodeError",
       "evalue": "'ascii' codec can't encode character u'\\u2019' in position 89: ordinal not in range(128)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-91-e9b84249fdd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msqlrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpanda_char\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean_disease_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-90-d027a45261a1>\u001b[0m in \u001b[0;36mconvert_to_sql\u001b[0;34m(pandadf, disease)\u001b[0m\n\u001b[1;32m     32\u001b[0m                          \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandadf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_contributions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\\",\\\"\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandadf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_revenue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\\",\\\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                          \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandadf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercent_program\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\\",\\\"\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandadf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercent_admin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\\",\\\"\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandadf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercent_fund\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                          + \"\\\",\\\"\" + str(facebook_likes_placeholder) + \"\\\",\\\"\" + str(pandadf.twitter_followers[idx]) + \"\\\"\")\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INSERT INTO \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"(name, disease, address, city, link, bbb_link, facebook_link, twitter_link, cn_link, bbb_accred,                          year_incorporated, purpose, board_size, staff_size, tax_status, cn_rated, cn_overall, cn_financial, cn_acct_transp,                          leader_compensation, total_expenses,                          total_contributions, total_revenue, percent_program, percent_admin, percent_fund, facebook_likes, twitter_followers)                          VALUES(\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\u2019' in position 89: ordinal not in range(128)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "panda_char[:1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>address</th>\n",
        "      <th>bbb_accred</th>\n",
        "      <th>bbb_link</th>\n",
        "      <th>board_size</th>\n",
        "      <th>city</th>\n",
        "      <th>cn_acct_transp</th>\n",
        "      <th>cn_financial</th>\n",
        "      <th>cn_link</th>\n",
        "      <th>cn_overall</th>\n",
        "      <th>cn_rated</th>\n",
        "      <th>disease</th>\n",
        "      <th>facebook_link</th>\n",
        "      <th>leader_compensation</th>\n",
        "      <th>link</th>\n",
        "      <th>name</th>\n",
        "      <th>percent_admin</th>\n",
        "      <th>percent_fund</th>\n",
        "      <th>percent_program</th>\n",
        "      <th>purpose</th>\n",
        "      <th>staff_size</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 34 Washington Street, Suite 200</td>\n",
        "      <td> Accredited Charity</td>\n",
        "      <td> http://www.give.org/charity-reviews/national/h...</td>\n",
        "      <td> 6</td>\n",
        "      <td> Wellesley Hills, MA 02481</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> http://www.charitynavigator.org/index.cfm?bay=...</td>\n",
        "      <td> 99.19</td>\n",
        "      <td> Rated</td>\n",
        "      <td> alzheimer</td>\n",
        "      <td> http://www.facebook.com/CureAlzheimers</td>\n",
        "      <td> $177,015</td>\n",
        "      <td> http://www.curealz.org</td>\n",
        "      <td> Cure Alzheimer's Fund</td>\n",
        "      <td> 6.8</td>\n",
        "      <td> 4.4</td>\n",
        "      <td> 88.6</td>\n",
        "      <td> to fund research with the highest probability ...</td>\n",
        "      <td> 6</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>1 rows \u00d7 27 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "                           address          bbb_accred  \\\n",
        "0  34 Washington Street, Suite 200  Accredited Charity   \n",
        "\n",
        "                                            bbb_link board_size  \\\n",
        "0  http://www.give.org/charity-reviews/national/h...          6   \n",
        "\n",
        "                        city  cn_acct_transp  cn_financial  \\\n",
        "0  Wellesley Hills, MA 02481               0             0   \n",
        "\n",
        "                                             cn_link  cn_overall cn_rated  \\\n",
        "0  http://www.charitynavigator.org/index.cfm?bay=...       99.19    Rated   \n",
        "\n",
        "     disease                           facebook_link leader_compensation  \\\n",
        "0  alzheimer  http://www.facebook.com/CureAlzheimers            $177,015   \n",
        "\n",
        "                     link                   name  percent_admin  percent_fund  \\\n",
        "0  http://www.curealz.org  Cure Alzheimer's Fund            6.8           4.4   \n",
        "\n",
        "   percent_program                                            purpose  \\\n",
        "0             88.6  to fund research with the highest probability ...   \n",
        "\n",
        "  staff_size      \n",
        "0          6 ...  \n",
        "\n",
        "[1 rows x 27 columns]"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "panda_char['purpose'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "u'to fund research with the highest probability of slowing, stopping or reversing Alzheimer\\u2019s through venture based philanthropy with all organizational expenses paid for by the Board, allowing all public contributions to directly fund Alzheimer\\u2019s disease research.'"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 303
    }
   ],
   "metadata": {}
  }
 ]
}